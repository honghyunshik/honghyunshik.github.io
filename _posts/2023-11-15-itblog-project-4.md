---
title: IT Blog 프로젝트 4일차 - 크롤링
author: honghyunshik
date: 2023-11-14 14:30:00 +0800
categories: [Project, SpringBoot]
tags: [springboot, selenium]
---

# 개요

오늘은 기존의 블로그 포스트들을 크롤링해서 제 Elastic Search 서버에 저장하도록 하겠습니다.

Elastic Search의 성능을 느껴보고 싶어서 이 프로젝트를 진행하게 되었기 때문에 최대한 많은 데이터를
저장하는 것이 좋을 것 같아요. 

    1. Tistory
    2. velog
    3. Github Pages

검색해보니 대표적으로 저렇게 3개의 기술 블로그가 존재하는 것 같아요.

제가 블로그 플랫폼들을 보면서 느낀건 velog는 좋아요로 순위도 매기면서 UI가 굉장히
잘 되어 있지만, Tistory와 Github Pages는 독자적인 개별 블로그 성향이 강합니다.

검색엔진에 의존해서 블로그가 노출되다 보니 접근성이 매우 떨어진다고 판단했습니다. 좋은 글을
작성해서 많은 좋아요 수를 받아도 크게 메리트가 없는 것 같습니다. 

이 점을 개선하기 위해서 접근성이 떨어지는 Tistory와 GitHub Pages의 포스트들을 
통합하여 velog처럼 트렌딩, 순위, 카테고리 등의 UI를 구축하려고 합니다.

## GitHub Pages 크롤링

제가 현재 사용하고 있는 플랫폼입니다. 저는 마크다운 랭기지, GitHub flow 등 학습을 위해
이 플랫폼을 선택했지만, 검색하기 매우 어렵습니다... 

포스트 점유율 자체가 Tistory와 velog가 압도적이다 보니 키워드로 검색을 해도
GitHub Page 플랫폼으로 작성된 포스트들은 노출되지 않습니다. 키워드를 통해 포스트를
검색하는 것은 포기해야 합니다.

다른 방법은 깃허브 검색창에 Advanced search를 통해 한국의 GitHub 블로그를 찾을 수 있긴 한데...

대부분의 GitHub Page는 정보성의 IT 관련 포스트를 올리는 것이 아닌, 자신을 PR하기 위한
포트폴리오 형식이 강했습니다. 

그리고 가장 중요한 것은 테마가 모두 달라 크롤링이 불가능합니다... 어쩔 수 없이 GitHub Pages의
포스트들은 포기하고 Tistory 스토리들로만 작업을 진행해야 할 것 같습니다.

## Tistory

결국 Tistory 만으로 DB를 구축하기로 했습니다. Tistory는 검색창에 검색을 하면 Daum
검색 엔진으로 이동 후 검색 결과가 반환되는 구조입니다. 결국 Daum 에다가 제가 직접
키워드를 입력하고, 직접 사이트를 방문하여 데이터를 뽑아내야 합니다.

뽑아낼 데이터는  작성자, 작성일, 제목, HTML 정도가 되겠습니다.

### 키워드

결국 다음에 검색 후 티스토리 블로그들을 크롤링 하는 것은 구현할 수 있지만, 어떤 것을 검색하느냐는
결국 제가 수작업으로 작성할 수 밖에 없습니다.

백엔드 관련 키워드를 챗 GPT에게 물어봤습니다. 200개를 해달라고 하니 진짜 200 개를 해주네요...
키워드 200개에 대해서 각각 10개의 검색결과 총 2000개를 DB에 저장하려고 합니다. 이 중에서 URL이 같은
포스트들도 분명 존재할 것이기 떄문에 최소 1500 개 이상의 데이터를 뽑아내도록 하겠습니다.









